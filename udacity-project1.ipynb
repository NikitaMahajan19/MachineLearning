{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from azureml.core import Workspace, Experiment\n\nws = Workspace.get(name=\"udacity-project\")\nexp = Experiment(workspace=ws, name=\"udacity-project\")\n\nprint('Workspace name: ' + ws.name, \n      'Azure region: ' + ws.location, \n      'Subscription id: ' + ws.subscription_id, \n      'Resource group: ' + ws.resource_group, sep = '\\n')\n\nrun = exp.start_logging()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\n\ncluster_name = \"project\"\n\ntry:\n    comp_target = ComputeTarget(workspace=ws, name=cluster_name)\n    print('Found existing cluster, use it.')\nexcept ComputeTargetException:\n    print('create new')\n    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n                                                           max_nodes=4)\n    comp_target = ComputeTarget.create(ws, cluster_name, compute_config)\n\ncompute_target.wait_for_completion(show_output=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from azureml.widgets import RunDetails\nfrom azureml.train.sklearn import SKLearn\nfrom azureml.train.hyperdrive.run import PrimaryMetricGoal\nfrom azureml.train.hyperdrive.policy import BanditPolicy\nfrom azureml.train.hyperdrive.sampling import RandomParameterSampling\nfrom azureml.train.hyperdrive.runconfig import HyperDriveConfig\nfrom azureml.train.hyperdrive.parameter_expressions import uniform\nimport os\n\n# Specify parameter sampler\nps = RandomParameterSampling( {\n        \"--C\": uniform(0.5, 10),\n        \"--max_iter\": choice( 10, 20, 40, 100)\n    }\n)\n\n# Specify a Policy\npolicy = BanditPolicy(slack_factor = 0.1, evaluation_interval = 2, delay_evaluation = 1)\n\nif \"training\" not in os.listdir():\n    os.mkdir(\"./training\")\n\n# Create a SKLearn estimator for use with train.py\nest = SKLearn(\"train.py\", compute_target=comp_target)\n\n# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\nhyperdrive_config = HyperDriveConfig(estimator=est,\n                             hyperparameter_sampling=ps,\n                             policy=policy,\n                             primary_metric_name=\"Accuracy\",\n                             primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n                             max_total_runs=12,\n                             max_concurrent_runs=4)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyper_run = exp.submit(hyperdrive_config)\n\nRunDetails(hyper_run).show()\n\nhyper_run.wait_for_completion(show_output=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\n# Get your best run and save the model from that run.\n\nhd_best_run = hyper_run.get_best_run_by_primary_metric()\nhd_best_run.get_details()\nhyper_run.get_children_sorted_by_primary_metric(top=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from azureml.data.dataset_factory import TabularDatasetFactory\n\n# Create TabularDataset using TabularDatasetFactory\n# Data is available at: \n# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n\nds = TabularDatasetFactory.from_delimited_files(path='https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from train import clean_data\n\n# Use the clean_data function to clean your data.\nx, y = clean_data(ds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from azureml.train.automl import AutoMLConfig\n\n# Set parameters for AutoMLConfig\n# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n# If you wish to run the experiment longer, you will need to run this notebook in your own\n# Azure tenant, which will incur personal costs.\n\nautoml_config = AutoMLConfig(\n    compute_target = comp_target,\n    experiment_timeout_minutes=30,\n    task=\"classification\",\n    primary_metric=\"accuracy\",\n    training_data = data,\n    label_column_name= \"y\",\n    n_cross_validations=5,\n    iterations = 12)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submit your automl run\n\nautomlrun = exp.submit(automl_config, show_output=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve and save your best automl model.\n\natml_best_run = automlrun.get_best_child()\n\natml_best_run.get_details()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cluster clean up\ncomp_target.delete()","metadata":{},"execution_count":null,"outputs":[]}]}
